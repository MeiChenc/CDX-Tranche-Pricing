{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOB8wAJ0f0CuhBnxQuv2gZg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MeiChenc/CDX-Tranche-Pricing/blob/main/CDX_Tranche_Pricing-2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jyZHIODaKW6i",
        "outputId": "f554d743-e06f-4a32-9db8-6026ab777e8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 125 constituents.\n",
            "Assumed index-level recovery: 0.40\n",
            "Available tenors in JSON: ['1Y', '2Y', '3Y', '5Y', '7Y', '10Y']\n",
            "Index full_index spreads (bps) per tenor:\n",
            "  1Y: 22.3900 bps\n",
            "  2Y: 30.0200 bps\n",
            "  3Y: 38.5900 bps\n",
            "  5Y: 51.9700 bps\n",
            "  7Y: 77.9900 bps\n",
            "  10Y: 95.5500 bps\n",
            "Bootstrapped lambda for tenor 1.0Y: 0.0037\n",
            "Bootstrapped lambda for tenor 2.0Y: 0.0063\n",
            "Bootstrapped lambda for tenor 3.0Y: 0.0094\n",
            "Bootstrapped lambda for tenor 5.0Y: 0.0123\n",
            "Bootstrapped lambda for tenor 7.0Y: 0.0256\n",
            "Bootstrapped lambda for tenor 10.0Y: 0.0247\n",
            "\n",
            "Piecewise-constant hazard rates (index level):\n",
            "  (0, 1.0Y] λ = 0.0037\n",
            "  (0, 2.0Y] λ = 0.0063\n",
            "  (0, 3.0Y] λ = 0.0094\n",
            "  (0, 5.0Y] λ = 0.0123\n",
            "  (0, 7.0Y] λ = 0.0256\n",
            "  (0, 10.0Y] λ = 0.0247\n",
            "Tenor 1.0Y: Q(T)=0.9963, PD(T)=0.0037\n",
            "Tenor 2.0Y: Q(T)=0.9900, PD(T)=0.0100\n",
            "Tenor 3.0Y: Q(T)=0.9807, PD(T)=0.0193\n",
            "Tenor 5.0Y: Q(T)=0.9568, PD(T)=0.0432\n",
            "Tenor 7.0Y: Q(T)=0.9090, PD(T)=0.0910\n",
            "Tenor 10.0Y: Q(T)=0.8442, PD(T)=0.1558\n",
            "\n",
            "=== Tenor 1.0Y ===\n",
            "Calibrated Gaussian rho_T: 0.5737\n",
            "Calibrated GVG params: {'rho_high': 0.5999999803003013, 'rho_low': 0.20000004028051876, 'p_high': 0.4999999513174274}\n",
            "\n",
            "Gaussian pricing vs market:\n",
            "      Tranche  Market      Model     Error Unit\n",
            "   equity_0_3  4.6922   4.842226  0.150026    %\n",
            "     mezz_3_7 52.9400 101.940575 49.000575  bps\n",
            "    mezz_7_10 21.6200  45.888481 24.268481  bps\n",
            " senior_10_15  5.2100  23.525368 18.315368  bps\n",
            "senior_15_100  4.7800   1.314134 -3.465866  bps\n",
            "Gaussian MAE (mix units): 19.0401\n",
            "\n",
            "GVG pricing vs market:\n",
            "      Tranche  Market     Model     Error Unit\n",
            "   equity_0_3  4.6922  5.633855  0.941655    %\n",
            "     mezz_3_7 52.9400 89.443779 36.503779  bps\n",
            "    mezz_7_10 21.6200 55.671393 34.051393  bps\n",
            " senior_10_15  5.2100 39.161021 33.951021  bps\n",
            "senior_15_100  4.7800 11.293450  6.513450  bps\n",
            "GVG MAE (mix units): 22.3923\n",
            "\n",
            "=== Tenor 2.0Y ===\n",
            "Calibrated Gaussian rho_T: 0.6099\n",
            "Calibrated GVG params: {'rho_high': 0.6, 'rho_low': 0.2, 'p_high': 0.5}\n",
            "\n",
            "Gaussian pricing vs market:\n",
            "      Tranche    Market      Model     Error Unit\n",
            "   equity_0_3 10.106963  10.163072  0.056109    %\n",
            "     mezz_3_7 90.940000 157.724359 66.784359  bps\n",
            "    mezz_7_10 40.630000  84.274396 43.644396  bps\n",
            " senior_10_15 14.330000  49.554244 35.224244  bps\n",
            "senior_15_100  8.300000   3.738604 -4.561396  bps\n",
            "Gaussian MAE (mix units): 30.0541\n",
            "\n",
            "GVG pricing vs market:\n",
            "      Tranche    Market      Model     Error Unit\n",
            "   equity_0_3 10.106963  15.077131  4.970168    %\n",
            "     mezz_3_7 90.940000 142.322504 51.382504  bps\n",
            "    mezz_7_10 40.630000  88.682243 48.052243  bps\n",
            " senior_10_15 14.330000  74.327970 59.997970  bps\n",
            "senior_15_100  8.300000  19.689950 11.389950  bps\n",
            "GVG MAE (mix units): 35.1586\n",
            "\n",
            "=== Tenor 3.0Y ===\n",
            "Calibrated Gaussian rho_T: 0.6215\n",
            "Calibrated GVG params: {'rho_high': 0.599999236840816, 'rho_low': 0.20000099818377698, 'p_high': 0.49999949577384073}\n",
            "\n",
            "Gaussian pricing vs market:\n",
            "      Tranche     Market      Model     Error Unit\n",
            "   equity_0_3  16.455602  16.467963  0.012361    %\n",
            "     mezz_3_7 133.100000 208.911899 75.811899  bps\n",
            "    mezz_7_10  63.540000 121.639599 58.099599  bps\n",
            " senior_10_15  26.450000  76.588877 50.138877  bps\n",
            "senior_15_100  12.730000   6.796399 -5.933601  bps\n",
            "Gaussian MAE (mix units): 37.9993\n",
            "\n",
            "GVG pricing vs market:\n",
            "      Tranche     Market      Model     Error Unit\n",
            "   equity_0_3  16.455602  22.451474  5.995872    %\n",
            "     mezz_3_7 133.100000 170.340946 37.240946  bps\n",
            "    mezz_7_10  63.540000  81.693125 18.153125  bps\n",
            " senior_10_15  26.450000  58.829729 32.379729  bps\n",
            "senior_15_100  12.730000  13.530287  0.800287  bps\n",
            "GVG MAE (mix units): 18.9140\n",
            "\n",
            "=== Tenor 5.0Y ===\n",
            "Calibrated Gaussian rho_T: 0.6389\n",
            "Calibrated GVG params: {'rho_high': 0.5999969173518686, 'rho_low': 0.20000377152989826, 'p_high': 0.4999978384898613}\n",
            "\n",
            "Gaussian pricing vs market:\n",
            "      Tranche   Market      Model      Error Unit\n",
            "   equity_0_3  28.3014  28.215806  -0.085594    %\n",
            "     mezz_3_7  95.0800 274.692054 179.612054  bps\n",
            "    mezz_7_10 113.1000 177.221381  64.121381  bps\n",
            " senior_10_15  55.9400 121.226891  65.286891  bps\n",
            "senior_15_100  21.7200  13.350001  -8.369999  bps\n",
            "Gaussian MAE (mix units): 63.4952\n",
            "\n",
            "GVG pricing vs market:\n",
            "      Tranche   Market      Model      Error Unit\n",
            "   equity_0_3  28.3014  39.257375  10.955975    %\n",
            "     mezz_3_7  95.0800 282.800477 187.720477  bps\n",
            "    mezz_7_10 113.1000 131.315273  18.215273  bps\n",
            " senior_10_15  55.9400  73.404805  17.464805  bps\n",
            "senior_15_100  21.7200  10.627058 -11.092942  bps\n",
            "GVG MAE (mix units): 49.0899\n",
            "\n",
            "=== Tenor 7.0Y ===\n",
            "Calibrated Gaussian rho_T: 0.6784\n",
            "Calibrated GVG params: {'rho_high': 0.6000011015386773, 'rho_low': 0.19999927474815035, 'p_high': 0.49999822975807595}\n",
            "\n",
            "Gaussian pricing vs market:\n",
            "      Tranche    Market      Model      Error Unit\n",
            "   equity_0_3  42.25299  42.176225  -0.076765    %\n",
            "     mezz_3_7 312.75000 377.473371  64.723371  bps\n",
            "    mezz_7_10 177.64000 269.989246  92.349246  bps\n",
            " senior_10_15  98.00000 201.836385 103.836385  bps\n",
            "senior_15_100  38.50000  28.822237  -9.677763  bps\n",
            "Gaussian MAE (mix units): 54.1327\n",
            "\n",
            "GVG pricing vs market:\n",
            "      Tranche    Market      Model      Error Unit\n",
            "   equity_0_3  42.25299  63.778133  21.525143    %\n",
            "     mezz_3_7 312.75000 522.052289 209.302289  bps\n",
            "    mezz_7_10 177.64000 284.000139 106.360139  bps\n",
            " senior_10_15  98.00000 165.946033  67.946033  bps\n",
            "senior_15_100  38.50000  19.493725 -19.006275  bps\n",
            "GVG MAE (mix units): 84.8280\n",
            "\n",
            "=== Tenor 10.0Y ===\n",
            "Calibrated Gaussian rho_T: 0.9900\n",
            "Calibrated GVG params: {'rho_high': 0.6000009902039762, 'rho_low': 0.19999960602801203, 'p_high': 0.5000013527052884}\n",
            "\n",
            "Gaussian pricing vs market:\n",
            "      Tranche     Market      Model       Error Unit\n",
            "   equity_0_3 -52.426298  20.921411   73.347709    %\n",
            "     mezz_3_7 377.470000 181.230284 -196.239716  bps\n",
            "    mezz_7_10 228.020000 172.383303  -55.636697  bps\n",
            " senior_10_15 135.870000 164.618388   28.748388  bps\n",
            "senior_15_100  54.110000  68.896998   14.786998  bps\n",
            "Gaussian MAE (mix units): 73.7519\n",
            "\n",
            "GVG pricing vs market:\n",
            "      Tranche     Market      Model      Error Unit\n",
            "   equity_0_3 -52.426298  83.644009 136.070307    %\n",
            "     mezz_3_7 377.470000 734.110222 356.640222  bps\n",
            "    mezz_7_10 228.020000 484.952733 256.932733  bps\n",
            " senior_10_15 135.870000 316.413855 180.543855  bps\n",
            "senior_15_100  54.110000  31.411912 -22.698088  bps\n",
            "GVG MAE (mix units): 190.5770\n",
            "\n",
            "Done. 'results_by_tenor' now holds detailed comparison tables and parameters for each tenor.\n"
          ]
        }
      ],
      "source": [
        "# ================================================================\n",
        "# 0. Setup: imports & file paths\n",
        "# ================================================================\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import json\n",
        "from typing import List, Dict\n",
        "from dataclasses import dataclass\n",
        "from scipy.optimize import root_scalar, minimize_scalar, minimize\n",
        "from scipy.stats import norm\n",
        "\n",
        "np.random.seed(42)  # for reproducibility\n",
        "\n",
        "# In Colab: upload these two files to the working directory first.\n",
        "CDX_CONST_FILE = \"cdx_constituents_multi_tenor.csv\"\n",
        "CDX_MARKET_FILE = \"cdx_market_data_multi_tenor.json\"\n",
        "\n",
        "\n",
        "# ================================================================\n",
        "# 1. Load data\n",
        "# ================================================================\n",
        "\n",
        "# 1.1 Load constituents (we only need number of names & equal weights; recovery set to 40%)\n",
        "const_df = pd.read_csv(CDX_CONST_FILE)\n",
        "NUM_NAMES = len(const_df)\n",
        "weights = np.ones(NUM_NAMES) / NUM_NAMES\n",
        "RECOVERY_IDX = 0.40   # standard market convention for CDX\n",
        "\n",
        "print(f\"Loaded {NUM_NAMES} constituents.\")\n",
        "print(f\"Assumed index-level recovery: {RECOVERY_IDX:.2f}\")\n",
        "\n",
        "# 1.2 Load multi-tenor market data (index + tranches)\n",
        "with open(CDX_MARKET_FILE, \"r\") as f:\n",
        "    mkt_multi = json.load(f)\n",
        "\n",
        "# Available tenors in years (keys like \"1Y\",\"2Y\",...)\n",
        "available_tenors = sorted(mkt_multi.keys(), key=lambda x: float(x.replace(\"Y\", \"\")))\n",
        "print(\"Available tenors in JSON:\", available_tenors)\n",
        "\n",
        "# We focus on these standard tenors:\n",
        "TENORS_YEARS = [1.0, 2.0, 3.0, 5.0, 7.0, 10.0]\n",
        "\n",
        "# Extract index \"full_index\" spreads in bps for each tenor\n",
        "index_spreads_bps = []\n",
        "for T in TENORS_YEARS:\n",
        "    key = f\"{int(T)}Y\"\n",
        "    full_index = mkt_multi[key][\"full_index\"]  # in bps\n",
        "    index_spreads_bps.append(full_index)\n",
        "\n",
        "print(\"Index full_index spreads (bps) per tenor:\")\n",
        "for T, s in zip(TENORS_YEARS, index_spreads_bps):\n",
        "    print(f\"  {T:.0f}Y: {s:.4f} bps\")\n",
        "\n",
        "\n",
        "# ================================================================\n",
        "# 2. Discount Curve (simple, but standard structure)\n",
        "# ================================================================\n",
        "\n",
        "@dataclass\n",
        "class DiscountCurve:\n",
        "    \"\"\"\n",
        "    Simple discount curve with flat continuously-compounded zero rate.\n",
        "    For demonstration we assume a flat risk-free rate.\n",
        "    \"\"\"\n",
        "    flat_rate: float  # e.g. 0.03 for 3%\n",
        "\n",
        "    def df(self, t: float) -> float:\n",
        "        if t <= 0.0:\n",
        "            return 1.0\n",
        "        return np.exp(-self.flat_rate * t)\n",
        "\n",
        "    def dfs(self, ts: np.ndarray) -> np.ndarray:\n",
        "        return np.exp(-self.flat_rate * ts)\n",
        "\n",
        "\n",
        "# For demo: assume flat OIS at 3%\n",
        "disc_curve = DiscountCurve(flat_rate=0.03)\n",
        "\n",
        "\n",
        "# ================================================================\n",
        "# 3. Standard CDS pricing & index hazard bootstrapping\n",
        "# ================================================================\n",
        "\n",
        "class CDSBootstrapper:\n",
        "    \"\"\"\n",
        "    Bootstrap piecewise-constant hazard rates from index CDS spreads\n",
        "    using standard CDS pricing equations:\n",
        "\n",
        "        PV_prem = S * sum(Δt * DF(t_i) * Q(t_i))\n",
        "        PV_prot = (1-R) * sum(DF(t_i) * [Q(t_{i-1}) - Q(t_i)])\n",
        "\n",
        "    where hazard is piecewise-constant by tenor.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, disc: DiscountCurve, recovery: float = 0.40, freq: int = 4):\n",
        "        self.disc = disc\n",
        "        self.R = recovery\n",
        "        self.freq = freq\n",
        "\n",
        "    @staticmethod\n",
        "    def _lambda_for_time(t: float,\n",
        "                         segment_tenors: List[float],\n",
        "                         segment_lambdas: List[float]) -> float:\n",
        "        \"\"\"\n",
        "        Given time t, find which tenor segment it belongs to, and return the corresponding lambda.\n",
        "        Segments are defined by increasing tenor boundaries: [T1, T2, ..., Tn].\n",
        "        On (0, T1] -> lambda_1, on (T1, T2] -> lambda_2, etc.\n",
        "        \"\"\"\n",
        "        for idx, T in enumerate(segment_tenors):\n",
        "            if t <= T + 1e-12:\n",
        "                return segment_lambdas[idx]\n",
        "        return segment_lambdas[-1]\n",
        "\n",
        "    def _build_survival_curve(self,\n",
        "                              coupons: np.ndarray,\n",
        "                              segment_tenors: List[float],\n",
        "                              segment_lambdas: List[float]) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Compute survival Q(t_i) at each coupon time using piecewise-constant hazard rates.\n",
        "        \"\"\"\n",
        "        surv = np.zeros_like(coupons, dtype=float)\n",
        "        cum_intensity = 0.0\n",
        "        prev_t = 0.0\n",
        "\n",
        "        for i, t in enumerate(coupons):\n",
        "            lam = self._lambda_for_time(t, segment_tenors, segment_lambdas)\n",
        "            dt = t - prev_t\n",
        "            cum_intensity += lam * dt\n",
        "            surv[i] = np.exp(-cum_intensity)\n",
        "            prev_t = t\n",
        "\n",
        "        return surv\n",
        "\n",
        "    def _cds_pv_equation(self,\n",
        "                         spread_dec: float,\n",
        "                         T: float,\n",
        "                         known_tenors: List[float],\n",
        "                         known_lambdas: List[float],\n",
        "                         lambda_new: float) -> float:\n",
        "        \"\"\"\n",
        "        Given known hazard segments (for previous tenors), and a trial lambda for the new segment,\n",
        "        compute PV_prem - PV_prot for target maturity T.\n",
        "        Root of this function w.r.t lambda_new yields the correct hazard rate for [T_{k-1}, T_k].\n",
        "        \"\"\"\n",
        "        segment_tenors = known_tenors + [T]\n",
        "        segment_lambdas = known_lambdas + [lambda_new]\n",
        "\n",
        "        dt = 1.0 / self.freq\n",
        "        coupons = np.arange(dt, T + 1e-12, dt)\n",
        "\n",
        "        dfs = self.disc.dfs(coupons)\n",
        "        surv = self._build_survival_curve(coupons, segment_tenors, segment_lambdas)\n",
        "\n",
        "        # Premium leg\n",
        "        pv_prem = np.sum(spread_dec * dt * dfs * surv)\n",
        "\n",
        "        # Protection leg\n",
        "        surv_prev = np.concatenate(([1.0], surv[:-1]))\n",
        "        default_prob = surv_prev - surv\n",
        "        pv_prot = np.sum((1.0 - self.R) * dfs * default_prob)\n",
        "\n",
        "        return pv_prem - pv_prot\n",
        "\n",
        "    def bootstrap_index_hazard(self,\n",
        "                               tenors: List[float],\n",
        "                               spreads_bps: List[float]) -> Dict[float, float]:\n",
        "        \"\"\"\n",
        "        Bootstrap piecewise-constant hazard rates from index CDS spreads.\n",
        "\n",
        "        tenors: [1, 2, 3, 5, 7, 10]\n",
        "        spreads_bps: index spreads in bps for these tenors.\n",
        "        return: {T_k: lambda_k} where lambda_k is intensity on (T_{k-1}, T_k].\n",
        "        \"\"\"\n",
        "        tenors = list(tenors)\n",
        "        spreads_bps = list(spreads_bps)\n",
        "\n",
        "        known_tenors: List[float] = []\n",
        "        known_lambdas: List[float] = []\n",
        "        hazard_by_tenor: Dict[float, float] = {}\n",
        "\n",
        "        for T, S_bps in zip(tenors, spreads_bps):\n",
        "            spread_dec = S_bps / 1e4  # bps -> decimal\n",
        "\n",
        "            def obj(lam_new):\n",
        "                return self._cds_pv_equation(spread_dec,\n",
        "                                             T,\n",
        "                                             known_tenors,\n",
        "                                             known_lambdas,\n",
        "                                             lam_new)\n",
        "\n",
        "            sol = root_scalar(obj, bracket=[1e-6, 10.0], method=\"brentq\")\n",
        "            lam_star = sol.root\n",
        "            known_tenors.append(T)\n",
        "            known_lambdas.append(lam_star)\n",
        "            hazard_by_tenor[T] = lam_star\n",
        "            print(f\"Bootstrapped lambda for tenor {T}Y: {lam_star:.4f}\")\n",
        "\n",
        "        return hazard_by_tenor\n",
        "\n",
        "\n",
        "# 3.1 Run hazard bootstrapping\n",
        "bootstrapper = CDSBootstrapper(disc_curve, recovery=RECOVERY_IDX, freq=4)\n",
        "hazard_curve = bootstrapper.bootstrap_index_hazard(TENORS_YEARS, index_spreads_bps)\n",
        "\n",
        "print(\"\\nPiecewise-constant hazard rates (index level):\")\n",
        "for T in sorted(hazard_curve.keys()):\n",
        "    print(f\"  (0, {T}Y] λ = {hazard_curve[T]:.4f}\")\n",
        "\n",
        "\n",
        "# ================================================================\n",
        "# 4. Survival & portfolio PD per tenor\n",
        "# ================================================================\n",
        "\n",
        "def index_survival_at_T(hazard_by_tenor: Dict[float, float], T: float) -> float:\n",
        "    \"\"\"\n",
        "    Compute index survival Q(T) given piecewise-constant hazard segments:\n",
        "      hazard_by_tenor: {T_k: lambda_k} for segments (T_{k-1}, T_k].\n",
        "    \"\"\"\n",
        "    tenors_sorted = sorted(hazard_by_tenor.keys())\n",
        "    cum_int = 0.0\n",
        "    prev = 0.0\n",
        "\n",
        "    for Tk in tenors_sorted:\n",
        "        lam = hazard_by_tenor[Tk]\n",
        "        seg_start = prev\n",
        "        seg_end = Tk\n",
        "        if T <= seg_start:\n",
        "            break\n",
        "        dt = min(T, seg_end) - seg_start\n",
        "        if dt > 0:\n",
        "            cum_int += lam * dt\n",
        "        prev = seg_end\n",
        "        if Tk >= T:\n",
        "            break\n",
        "\n",
        "    return float(np.exp(-cum_int))\n",
        "\n",
        "\n",
        "PD_by_tenor: Dict[float, float] = {}\n",
        "for T in TENORS_YEARS:\n",
        "    Q_T = index_survival_at_T(hazard_curve, T)\n",
        "    PD_T = 1.0 - Q_T\n",
        "    PD_by_tenor[T] = PD_T\n",
        "    print(f\"Tenor {T}Y: Q(T)={Q_T:.4f}, PD(T)={PD_T:.4f}\")\n",
        "\n",
        "\n",
        "# ================================================================\n",
        "# 5. Gaussian Copula tranche pricer\n",
        "# ================================================================\n",
        "\n",
        "class GaussianCopulaTranchePricer:\n",
        "    \"\"\"\n",
        "    One-factor Gaussian copula under LHP approximation for tranche loss at maturity.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, rho: float, n_points: int = 501):\n",
        "        self.rho = rho\n",
        "        self.Y = np.linspace(-5.0, 5.0, n_points)\n",
        "        pdf = norm.pdf(self.Y)\n",
        "        dy = self.Y[1] - self.Y[0]\n",
        "        self.weights = pdf * dy / np.sum(pdf * dy)\n",
        "\n",
        "    def conditional_pd(self, PD_T: float, y: float) -> float:\n",
        "        PD_T = np.clip(PD_T, 1e-8, 1.0 - 1e-8)\n",
        "        K = norm.ppf(PD_T)\n",
        "        num = K - np.sqrt(self.rho) * y\n",
        "        den = np.sqrt(1.0 - self.rho)\n",
        "        return float(norm.cdf(num / den))\n",
        "\n",
        "    def tranche_el(self,\n",
        "                   PD_T: float,\n",
        "                   attach: float,\n",
        "                   detach: float,\n",
        "                   recovery: float = 0.40) -> float:\n",
        "        \"\"\"\n",
        "        Expected tranche loss as fraction of tranche notional.\n",
        "        \"\"\"\n",
        "        lgd = 1.0 - recovery\n",
        "        width = detach - attach\n",
        "\n",
        "        losses = np.zeros_like(self.Y, dtype=float)\n",
        "        for i, y in enumerate(self.Y):\n",
        "            cond_pd = self.conditional_pd(PD_T, y)\n",
        "            L = lgd * cond_pd   # LHP approx\n",
        "            losses[i] = np.clip(L - attach, 0.0, width) / width\n",
        "\n",
        "        EL = float(np.sum(losses * self.weights))\n",
        "        return EL\n",
        "\n",
        "\n",
        "def fair_tranche_spread(discount_curve: DiscountCurve,\n",
        "                        maturity: float,\n",
        "                        EL_T: float,\n",
        "                        recovery: float = 0.40,\n",
        "                        freq: int = 4) -> float:\n",
        "    \"\"\"\n",
        "    Approximate fair running spread for a tranche given expected loss at maturity.\n",
        "    This is a standard approximation:\n",
        "      - premium leg uses average outstanding tranche notional\n",
        "      - protection leg approximated by EL_T discounted to T.\n",
        "    \"\"\"\n",
        "    dt = 1.0 / freq\n",
        "    payment_times = np.arange(dt, maturity + 1e-12, dt)\n",
        "    dfs = discount_curve.dfs(payment_times)\n",
        "\n",
        "    # Approximate average outstanding tranche notional\n",
        "    avg_notional = 1.0 - 0.5 * EL_T\n",
        "    risky_pv01 = float(np.sum(dfs * dt * avg_notional))\n",
        "\n",
        "    df_T = discount_curve.df(maturity)\n",
        "    pv_prot = EL_T * df_T\n",
        "\n",
        "    s = pv_prot / risky_pv01  # decimal (e.g. 0.02 = 200 bps)\n",
        "    return float(s)\n",
        "\n",
        "\n",
        "def price_tranches_gaussian(PD_T: float,\n",
        "                            rho: float,\n",
        "                            disc_curve: DiscountCurve,\n",
        "                            maturity: float,\n",
        "                            recovery: float = 0.40) -> Dict[str, Dict[str, float]]:\n",
        "    copula = GaussianCopulaTranchePricer(rho)\n",
        "    tr_defs = [\n",
        "        (\"equity_0_3\", 0.00, 0.03),\n",
        "        (\"mezz_3_7\",   0.03, 0.07),\n",
        "        (\"mezz_7_10\",  0.07, 0.10),\n",
        "        (\"senior_10_15\", 0.10, 0.15),\n",
        "        (\"senior_15_100\", 0.15, 1.00),\n",
        "    ]\n",
        "    results = {}\n",
        "    for name, A, B in tr_defs:\n",
        "        EL = copula.tranche_el(PD_T, A, B, recovery)\n",
        "        s = fair_tranche_spread(disc_curve, maturity, EL, recovery)\n",
        "        results[name] = {\"EL\": EL, \"spread\": s}\n",
        "    return results\n",
        "\n",
        "\n",
        "# ================================================================\n",
        "# 6. Variance-Gamma sampler + GVG Copula pricer\n",
        "# ================================================================\n",
        "\n",
        "import numpy as np\n",
        "from scipy.stats import norm\n",
        "\n",
        "def sample_variance_gamma(n, theta=0.0, sigma=1.0, nu=1.0):\n",
        "    \"\"\"Generate Variance-Gamma samples via Gamma-Normal mixture.\"\"\"\n",
        "    G = np.random.gamma(shape=nu/2.0, scale=2.0/nu, size=n)\n",
        "    Z = np.random.normal(size=n)\n",
        "    return theta * G + sigma * np.sqrt(G) * Z\n",
        "\n",
        "\n",
        "class GVGCopulaTranchePricer:\n",
        "    \"\"\"\n",
        "    GVG copula with mixture correlation structure.\n",
        "\n",
        "    The interface is intentionally designed to match GaussianCopulaTranchePricer:\n",
        "       - portfolio_loss(PD_T, recovery)\n",
        "       - tranche_el(losses, probs, attach, detach)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 rho_high: float,\n",
        "                 rho_low: float,\n",
        "                 p_high: float,\n",
        "                 n_points: int = 2000,\n",
        "                 theta: float = 0.0,\n",
        "                 sigma: float = 1.0,\n",
        "                 nu: float = 1.0):\n",
        "\n",
        "        self.rho_high = rho_high\n",
        "        self.rho_low = rho_low\n",
        "        self.p_high = p_high\n",
        "        self.theta = theta\n",
        "        self.sigma = sigma\n",
        "        self.nu = nu\n",
        "\n",
        "        # number of scenarios\n",
        "        n_high = int(n_points * p_high)\n",
        "        n_low = n_points - n_high\n",
        "\n",
        "        # High-correlation VG samples\n",
        "        Y_high = sample_variance_gamma(\n",
        "            n_high, theta=self.theta, sigma=self.sigma, nu=self.nu\n",
        "        )\n",
        "\n",
        "        # Low-correlation Gaussian samples\n",
        "        Y_low = np.random.normal(size=n_low)\n",
        "\n",
        "        # Combine scenarios\n",
        "        self.Y = np.concatenate([Y_high, Y_low])\n",
        "\n",
        "        # Mixture indicator (match array size)\n",
        "        self.is_high = np.concatenate([\n",
        "            np.ones(n_high, dtype=bool),\n",
        "            np.zeros(n_low, dtype=bool)\n",
        "        ])\n",
        "\n",
        "        # equal weights\n",
        "        self.weights = np.ones_like(self.Y) / len(self.Y)\n",
        "\n",
        "\n",
        "    def conditional_pd(self, PD, Y, rho):\n",
        "        \"\"\"Conditional PD under Gaussian conditional structure.\"\"\"\n",
        "        if PD <= 0 or PD >= 1:\n",
        "            return max(0, min(1, PD))\n",
        "        K = norm.ppf(PD)\n",
        "        return norm.cdf((K - np.sqrt(rho)*Y) / np.sqrt(1 - rho))\n",
        "\n",
        "\n",
        "    def portfolio_loss(self, PD_T, recovery=0.40):\n",
        "        \"\"\"\n",
        "        Compute the portfolio expected loss conditional on each Y scenario.\n",
        "        OUTPUT:\n",
        "            losses : array of expected portfolio loss [% of notional]\n",
        "            probs  : scenario weights\n",
        "        \"\"\"\n",
        "        lgd = 1 - recovery\n",
        "        losses = np.zeros(len(self.Y))\n",
        "\n",
        "        for i, (Y, isH) in enumerate(zip(self.Y, self.is_high)):\n",
        "            rho = self.rho_high if isH else self.rho_low\n",
        "            cond_pd = self.conditional_pd(PD_T, Y, rho)\n",
        "            losses[i] = lgd * cond_pd\n",
        "\n",
        "        return losses, self.weights\n",
        "\n",
        "\n",
        "    def tranche_el(self, losses, probs, attach, detach):\n",
        "        \"\"\"\n",
        "        Compute expected loss of a tranche.\n",
        "        \"\"\"\n",
        "        width = detach - attach\n",
        "        tr_loss = np.maximum(0, np.minimum(losses - attach, width)) / width\n",
        "        return np.sum(tr_loss * probs)\n",
        "\n",
        "\n",
        "\n",
        "def price_tranches_gvg(PD_T,\n",
        "                       rho_high,\n",
        "                       rho_low,\n",
        "                       p_high,\n",
        "                       disc_curve,\n",
        "                       maturity,\n",
        "                       recovery=0.40):\n",
        "    \"\"\"\n",
        "    Full GVG tranche pricer aligned with Gaussian interface.\n",
        "    Returns a dict identical to price_tranches_gaussian().\n",
        "    \"\"\"\n",
        "\n",
        "    # 1. 建立 GVG copula 物件\n",
        "    copula = GVGCopulaTranchePricer(\n",
        "        rho_high=rho_high,\n",
        "        rho_low=rho_low,\n",
        "        p_high=p_high\n",
        "    )\n",
        "\n",
        "    # 2. Monte Carlo / grid：計算 portfolio loss distribution\n",
        "    losses, weights = copula.portfolio_loss(PD_T, recovery)\n",
        "\n",
        "    # 3. Discount curve\n",
        "    payment_dates = np.arange(0.25, maturity + 0.25, 0.25)\n",
        "    dfs = np.array([disc_curve.df(t) for t in payment_dates])\n",
        "\n",
        "    # 4. Tranche definitions\n",
        "    tranches = {\n",
        "        \"equity_0_3\":  (0.00, 0.03),\n",
        "        \"mezz_3_7\":    (0.03, 0.07),\n",
        "        \"mezz_7_10\":   (0.07, 0.10),\n",
        "        \"senior_10_15\":(0.10, 0.15),\n",
        "        \"senior_15_100\":(0.15, 1.00),\n",
        "    }\n",
        "\n",
        "    result = {}\n",
        "\n",
        "    for name, (attach, detach) in tranches.items():\n",
        "\n",
        "        # expected loss (EL)\n",
        "        el = copula.tranche_el(losses, weights, attach, detach)\n",
        "\n",
        "        if name == \"equity_0_3\":\n",
        "            # Upfront pricing: EL 對應 0–3% loss\n",
        "            result[name] = {\n",
        "                \"EL\": el,\n",
        "                \"spread\": 0.0\n",
        "            }\n",
        "        else:\n",
        "            # Running spread (approx) = EL / RPV01\n",
        "            avg_surv = 1 - PD_T\n",
        "            rpv01 = np.sum(dfs * avg_surv * 0.25)\n",
        "\n",
        "            spread_decimal = el / rpv01\n",
        "            result[name] = {\n",
        "                \"EL\": el,\n",
        "                \"spread\": spread_decimal\n",
        "            }\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "\n",
        "# ================================================================\n",
        "# 7. Calibration & pricing error per tenor\n",
        "# ================================================================\n",
        "\n",
        "def get_market_tranche_quotes_for_tenor(tenor_years: float) -> Dict[str, float]:\n",
        "    \"\"\"\n",
        "    Extract market tranche quotes for a given tenor T from the JSON structure.\n",
        "    Returns:\n",
        "      {\n",
        "        'equity_0_3_upfront': float (%),\n",
        "        'equity_0_3_running': float (bps),\n",
        "        'mezz_3_7': float (bps),\n",
        "        'mezz_7_10': float (bps),\n",
        "        'senior_10_15': float (bps),\n",
        "        'senior_15_100': float (bps)\n",
        "      }\n",
        "    \"\"\"\n",
        "    key = f\"{int(tenor_years)}Y\"\n",
        "    d = mkt_multi[key]\n",
        "    out = {\n",
        "        \"equity_0_3_upfront\": d[\"equity_0_3_upfront\"],\n",
        "        \"equity_0_3_running\": d[\"equity_0_3_running\"],\n",
        "        \"mezz_3_7\": d[\"mezz_3_7\"],\n",
        "        \"mezz_7_10\": d[\"mezz_7_10\"],\n",
        "        \"senior_10_15\": d[\"senior_10_15\"],\n",
        "        \"senior_15_100\": d[\"senior_15_100\"],\n",
        "    }\n",
        "    return out\n",
        "\n",
        "\n",
        "def calibrate_gaussian_for_tenor(\n",
        "        PD_T: float,\n",
        "        disc_curve: DiscountCurve,\n",
        "        maturity: float,\n",
        "        mkt_quotes: Dict[str, float],\n",
        "        recovery: float = 0.40):\n",
        "\n",
        "    def objective(rho: float) -> float:\n",
        "        if not (0 < rho < 1):\n",
        "            return 1e9\n",
        "\n",
        "        prices = price_tranches_gaussian(\n",
        "            PD_T,\n",
        "            rho,\n",
        "            disc_curve,\n",
        "            maturity,\n",
        "            recovery\n",
        "        )\n",
        "\n",
        "        # Equity upfront (%)\n",
        "        model_up = prices[\"equity_0_3\"][\"EL\"] * 100.0\n",
        "        mkt_up = mkt_quotes[\"equity_0_3_upfront\"]\n",
        "        # 放大到 bps 等級再平方，避免被其他 tranche 吃掉\n",
        "        eq_err = ((model_up - mkt_up) * 100.0) ** 2\n",
        "\n",
        "        # Other tranches (bps)\n",
        "        err_others = 0.0\n",
        "        for name in [\"mezz_3_7\", \"mezz_7_10\", \"senior_10_15\", \"senior_15_100\"]:\n",
        "            model_bps = prices[name][\"spread\"] * 1e4  # decimal → bps\n",
        "            mkt_bps   = mkt_quotes[name]\n",
        "            err_others += (model_bps - mkt_bps) ** 2\n",
        "\n",
        "        return eq_err + err_others\n",
        "\n",
        "    res = minimize_scalar(\n",
        "        objective,\n",
        "        bounds=(0.01, 0.99),\n",
        "        method=\"bounded\"\n",
        "    )\n",
        "    return float(res.x)\n",
        "\n",
        "\n",
        "def calibrate_gvg_for_tenor(\n",
        "        PD_T: float,\n",
        "        disc_curve: DiscountCurve,\n",
        "        maturity: float,\n",
        "        mkt_quotes: Dict[str, float],\n",
        "        recovery: float = 0.40):\n",
        "\n",
        "    def objective(x: np.ndarray) -> float:\n",
        "        rho_high, rho_low, p_high = x\n",
        "\n",
        "        # Boundaries\n",
        "        if not (0 < rho_low < rho_high < 1):\n",
        "            return 1e9\n",
        "        if not (0 < p_high < 1):\n",
        "            return 1e9\n",
        "\n",
        "        prices = price_tranches_gvg(\n",
        "            PD_T,\n",
        "            rho_high,\n",
        "            rho_low,\n",
        "            p_high,\n",
        "            disc_curve,\n",
        "            maturity,\n",
        "            recovery\n",
        "        )\n",
        "\n",
        "        # Equity upfront (%)\n",
        "        model_up = prices[\"equity_0_3\"][\"EL\"] * 100.0\n",
        "        mkt_up = mkt_quotes[\"equity_0_3_upfront\"]\n",
        "        eq_err = ((model_up - mkt_up) * 100.0) ** 2\n",
        "\n",
        "        # Other tranches (bps)\n",
        "        err_others = 0.0\n",
        "        for name in [\"mezz_3_7\", \"mezz_7_10\", \"senior_10_15\", \"senior_15_100\"]:\n",
        "            model_bps = prices[name][\"spread\"] * 1e4\n",
        "            mkt_bps   = mkt_quotes[name]\n",
        "            err_others += (model_bps - mkt_bps) ** 2\n",
        "\n",
        "        return eq_err + err_others\n",
        "\n",
        "    init = np.array([0.6, 0.2, 0.5])\n",
        "    bnds = [(0.01, 0.99), (0.01, 0.99), (0.01, 0.99)]\n",
        "\n",
        "    res = minimize(\n",
        "        objective,\n",
        "        init,\n",
        "        bounds=bnds,\n",
        "        method=\"L-BFGS-B\"\n",
        "    )\n",
        "\n",
        "    rho_high, rho_low, p_high = res.x\n",
        "    return float(rho_high), float(rho_low), float(p_high)\n",
        "\n",
        "\n",
        "def compute_pricing_errors_for_tenor(T: float,\n",
        "                                     PD_T: float,\n",
        "                                     disc_curve: DiscountCurve,\n",
        "                                     recovery: float = 0.40) -> Dict[str, object]:\n",
        "    \"\"\"\n",
        "    For a given tenor T:\n",
        "      - calibrate Gaussian rho_T\n",
        "      - calibrate GVG parameters\n",
        "      - price all tranches under both models\n",
        "      - compute pricing errors vs market quotes\n",
        "    Returns:\n",
        "      dict with DataFrames for Gaussian and GVG comparison tables and MAE metrics.\n",
        "    \"\"\"\n",
        "    mkt_quotes = get_market_tranche_quotes_for_tenor(T)\n",
        "\n",
        "    # 1) Gaussian calibration & pricing\n",
        "    rho_T = calibrate_gaussian_for_tenor(PD_T, disc_curve, T, mkt_quotes, recovery)\n",
        "    gauss_prices = price_tranches_gaussian(PD_T, rho_T, disc_curve, T, recovery)\n",
        "\n",
        "    # 2) GVG calibration & pricing\n",
        "    rho_high, rho_low, p_high = calibrate_gvg_for_tenor(\n",
        "        PD_T, disc_curve, T, mkt_quotes, recovery\n",
        "    )\n",
        "    gvg_prices = price_tranches_gvg(\n",
        "        PD_T,\n",
        "        rho_high,\n",
        "        rho_low,\n",
        "        p_high,\n",
        "        disc_curve,\n",
        "        T,\n",
        "        recovery\n",
        "    )\n",
        "\n",
        "    # 整理結果表\n",
        "    rows_gauss = []\n",
        "    rows_gvg = []\n",
        "\n",
        "    for name in [\"equity_0_3\", \"mezz_3_7\", \"mezz_7_10\", \"senior_10_15\", \"senior_15_100\"]:\n",
        "        if name == \"equity_0_3\":\n",
        "            # Upfront comparison (%)\n",
        "            mkt_val = mkt_quotes[\"equity_0_3_upfront\"]\n",
        "            model_gauss = gauss_prices[name][\"EL\"] * 100.0\n",
        "            model_gvg   = gvg_prices[name][\"EL\"] * 100.0\n",
        "            unit = \"%\"\n",
        "        else:\n",
        "            # Running spread comparison (bps)\n",
        "            mkt_val = mkt_quotes[name]\n",
        "            model_gauss = gauss_prices[name][\"spread\"] * 1e4\n",
        "            model_gvg   = gvg_prices[name][\"spread\"] * 1e4\n",
        "            unit = \"bps\"\n",
        "\n",
        "        rows_gauss.append({\n",
        "            \"Tranche\": name,\n",
        "            \"Market\": mkt_val,\n",
        "            \"Model\": model_gauss,\n",
        "            \"Error\": model_gauss - mkt_val,\n",
        "            \"Unit\": unit,\n",
        "        })\n",
        "        rows_gvg.append({\n",
        "            \"Tranche\": name,\n",
        "            \"Market\": mkt_val,\n",
        "            \"Model\": model_gvg,\n",
        "            \"Error\": model_gvg - mkt_val,\n",
        "            \"Unit\": unit,\n",
        "        })\n",
        "\n",
        "    df_gauss = pd.DataFrame(rows_gauss)\n",
        "    df_gvg = pd.DataFrame(rows_gvg)\n",
        "\n",
        "    mae_gauss = df_gauss[\"Error\"].abs().mean()\n",
        "    mae_gvg   = df_gvg[\"Error\"].abs().mean()\n",
        "\n",
        "    # 組 GVG 參數 dict，避免 name 'gvg_params' 未定義\n",
        "    gvg_params = {\n",
        "        \"rho_high\": rho_high,\n",
        "        \"rho_low\":  rho_low,\n",
        "        \"p_high\":   p_high,\n",
        "    }\n",
        "\n",
        "    print(f\"\\n=== Tenor {T}Y ===\")\n",
        "    print(f\"Calibrated Gaussian rho_T: {rho_T:.4f}\")\n",
        "    print(f\"Calibrated GVG params: {gvg_params}\")\n",
        "\n",
        "    print(\"\\nGaussian pricing vs market:\")\n",
        "    print(df_gauss.to_string(index=False))\n",
        "    print(f\"Gaussian MAE (mix units): {mae_gauss:.4f}\")\n",
        "\n",
        "    print(\"\\nGVG pricing vs market:\")\n",
        "    print(df_gvg.to_string(index=False))\n",
        "    print(f\"GVG MAE (mix units): {mae_gvg:.4f}\")\n",
        "\n",
        "    return {\n",
        "        \"gaussian\":   df_gauss,\n",
        "        \"gvg\":        df_gvg,\n",
        "        \"rho_gauss\":  rho_T,\n",
        "        \"params_gvg\": gvg_params,\n",
        "        \"mae_gauss\":  mae_gauss,\n",
        "        \"mae_gvg\":    mae_gvg,\n",
        "    }\n",
        "\n",
        "\n",
        "# ================================================================\n",
        "# 8. Run experiment across all tenors\n",
        "# ================================================================\n",
        "\n",
        "results_by_tenor = {}\n",
        "\n",
        "for T in TENORS_YEARS:\n",
        "    PD_T = PD_by_tenor[T]\n",
        "    res_T = compute_pricing_errors_for_tenor(T, PD_T, disc_curve, RECOVERY_IDX)\n",
        "    results_by_tenor[T] = res_T\n",
        "\n",
        "print(\"\\nDone. 'results_by_tenor' now holds detailed comparison tables and parameters for each tenor.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "rows = []\n",
        "for T, res in results_by_tenor.items():\n",
        "    rows.append({\n",
        "        \"tenor_years\": T,\n",
        "        \"rho_gauss\": res[\"rho_gauss\"],\n",
        "        \"rho_high_gvg\": res[\"params_gvg\"][\"rho_high\"],\n",
        "        \"rho_low_gvg\": res[\"params_gvg\"][\"rho_low\"],\n",
        "        \"p_high_gvg\": res[\"params_gvg\"][\"p_high\"],\n",
        "        \"mae_gauss\": res[\"mae_gauss\"],\n",
        "        \"mae_gvg\": res[\"mae_gvg\"],\n",
        "    })\n",
        "\n",
        "df_summary = pd.DataFrame(rows).sort_values(\"tenor_years\")\n",
        "df_summary.to_csv(\"pricing_summary_by_tenor.csv\", index=False)\n",
        "\n",
        "df_summary\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "DE_7fyB5mT7a",
        "outputId": "7963213b-90c2-4092-e0ff-515544c72519"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   tenor_years  rho_gauss  rho_high_gvg  rho_low_gvg  p_high_gvg  mae_gauss  \\\n",
              "0          1.0   0.573740      0.600000     0.200000    0.500000  19.040063   \n",
              "1          2.0   0.609946      0.600000     0.200000    0.500000  30.054101   \n",
              "2          3.0   0.621469      0.599999     0.200001    0.499999  37.999267   \n",
              "3          5.0   0.638874      0.599997     0.200004    0.499998  63.495184   \n",
              "4          7.0   0.678418      0.600001     0.199999    0.499998  54.132706   \n",
              "5         10.0   0.989994      0.600001     0.200000    0.500001  73.751902   \n",
              "\n",
              "      mae_gvg  \n",
              "0   22.392260  \n",
              "1   35.158567  \n",
              "2   18.913992  \n",
              "3   49.089894  \n",
              "4   84.827976  \n",
              "5  190.577041  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-65a41544-0529-43a4-a590-a8b8a750566e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tenor_years</th>\n",
              "      <th>rho_gauss</th>\n",
              "      <th>rho_high_gvg</th>\n",
              "      <th>rho_low_gvg</th>\n",
              "      <th>p_high_gvg</th>\n",
              "      <th>mae_gauss</th>\n",
              "      <th>mae_gvg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.573740</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>19.040063</td>\n",
              "      <td>22.392260</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.0</td>\n",
              "      <td>0.609946</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>30.054101</td>\n",
              "      <td>35.158567</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3.0</td>\n",
              "      <td>0.621469</td>\n",
              "      <td>0.599999</td>\n",
              "      <td>0.200001</td>\n",
              "      <td>0.499999</td>\n",
              "      <td>37.999267</td>\n",
              "      <td>18.913992</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5.0</td>\n",
              "      <td>0.638874</td>\n",
              "      <td>0.599997</td>\n",
              "      <td>0.200004</td>\n",
              "      <td>0.499998</td>\n",
              "      <td>63.495184</td>\n",
              "      <td>49.089894</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7.0</td>\n",
              "      <td>0.678418</td>\n",
              "      <td>0.600001</td>\n",
              "      <td>0.199999</td>\n",
              "      <td>0.499998</td>\n",
              "      <td>54.132706</td>\n",
              "      <td>84.827976</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>10.0</td>\n",
              "      <td>0.989994</td>\n",
              "      <td>0.600001</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.500001</td>\n",
              "      <td>73.751902</td>\n",
              "      <td>190.577041</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-65a41544-0529-43a4-a590-a8b8a750566e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-65a41544-0529-43a4-a590-a8b8a750566e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-65a41544-0529-43a4-a590-a8b8a750566e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-1fff8af9-11ea-40aa-913f-5362e5cfc6e1\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1fff8af9-11ea-40aa-913f-5362e5cfc6e1')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-1fff8af9-11ea-40aa-913f-5362e5cfc6e1 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_424c4756-dbac-4897-ad4d-8c69cc5a0bfd\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_summary')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_424c4756-dbac-4897-ad4d-8c69cc5a0bfd button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_summary');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_summary",
              "summary": "{\n  \"name\": \"df_summary\",\n  \"rows\": 6,\n  \"fields\": [\n    {\n      \"column\": \"tenor_years\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.386246693120078,\n        \"min\": 1.0,\n        \"max\": 10.0,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          1.0,\n          2.0,\n          10.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rho_gauss\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1531269624740443,\n        \"min\": 0.5737404726140544,\n        \"max\": 0.9899941583562332,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.5737404726140544,\n          0.6099464058845276,\n          0.9899941583562332\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rho_high_gvg\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.5332995505158618e-06,\n        \"min\": 0.5999969173518686,\n        \"max\": 0.6000011015386773,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.5999999803003013,\n          0.6,\n          0.6000009902039762\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rho_low_gvg\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.6512624068712407e-06,\n        \"min\": 0.19999927474815035,\n        \"max\": 0.20000377152989826,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.20000004028051876,\n          0.2,\n          0.19999960602801203\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"p_high_gvg\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.285103156217517e-06,\n        \"min\": 0.4999978384898613,\n        \"max\": 0.5000013527052884,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.4999999513174274,\n          0.5,\n          0.5000013527052884\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mae_gauss\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 20.91168361446442,\n        \"min\": 19.040063111143958,\n        \"max\": 73.75190157757778,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          19.040063111143958,\n          30.0541007533133,\n          73.75190157757778\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mae_gvg\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 65.15474638782257,\n        \"min\": 18.913991610956046,\n        \"max\": 190.57704107329093,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          22.392259653740847,\n          35.158566964244926,\n          190.57704107329093\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.makedirs(\"results\", exist_ok=True)\n",
        "\n",
        "for T, res in results_by_tenor.items():\n",
        "    # Gaussian 結果\n",
        "    res[\"gaussian\"].to_csv(f\"results/gaussian_{int(T)}Y.csv\", index=False)\n",
        "    # GVG 結果\n",
        "    res[\"gvg\"].to_csv(f\"results/gvg_{int(T)}Y.csv\", index=False)\n",
        "\n",
        "print(\"CSV files saved under ./results/\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oN5KDCmxiVg5",
        "outputId": "f081ff84-4281-4263-cb70-6fbb01e165a4"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV files saved under ./results/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"results/calibration_gaussian_5Y.csv\")\n",
        "plt.plot(df[\"rho\"], df[\"loss\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "id": "fJ47UetAi-uN",
        "outputId": "84a4a6af-630d-4a58-de01-ea9941e94b43"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'results/calibration_gaussian_5Y.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-830432659.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"results/calibration_gaussian_5Y.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"rho\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'results/calibration_gaussian_5Y.csv'"
          ]
        }
      ]
    }
  ]
}