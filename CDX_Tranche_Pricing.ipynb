{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNsRGpVZqkjLyxE30QL9xl0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MeiChenc/CDX-Tranche-Pricing/blob/main/CDX_Tranche_Pricing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jyZHIODaKW6i",
        "outputId": "d22aca25-c478-426d-e9e2-d71e566b7973"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 125 constituents.\n",
            "Assumed index-level recovery: 0.40\n",
            "Available tenors in JSON: ['1Y', '2Y', '3Y', '5Y', '7Y', '10Y']\n",
            "Index full_index spreads (bps) per tenor:\n",
            "  1Y: 22.3900 bps\n",
            "  2Y: 30.0200 bps\n",
            "  3Y: 38.5900 bps\n",
            "  5Y: 51.9700 bps\n",
            "  7Y: 77.9900 bps\n",
            "  10Y: 95.5500 bps\n",
            "Bootstrapped lambda for tenor 1.0Y: 0.0037\n",
            "Bootstrapped lambda for tenor 2.0Y: 0.0063\n",
            "Bootstrapped lambda for tenor 3.0Y: 0.0094\n",
            "Bootstrapped lambda for tenor 5.0Y: 0.0123\n",
            "Bootstrapped lambda for tenor 7.0Y: 0.0256\n",
            "Bootstrapped lambda for tenor 10.0Y: 0.0247\n",
            "\n",
            "Piecewise-constant hazard rates (index level):\n",
            "  (0, 1.0Y] λ = 0.0037\n",
            "  (0, 2.0Y] λ = 0.0063\n",
            "  (0, 3.0Y] λ = 0.0094\n",
            "  (0, 5.0Y] λ = 0.0123\n",
            "  (0, 7.0Y] λ = 0.0256\n",
            "  (0, 10.0Y] λ = 0.0247\n",
            "Tenor 1.0Y: Q(T)=0.9963, PD(T)=0.0037\n",
            "Tenor 2.0Y: Q(T)=0.9900, PD(T)=0.0100\n",
            "Tenor 3.0Y: Q(T)=0.9807, PD(T)=0.0193\n",
            "Tenor 5.0Y: Q(T)=0.9568, PD(T)=0.0432\n",
            "Tenor 7.0Y: Q(T)=0.9090, PD(T)=0.0910\n",
            "Tenor 10.0Y: Q(T)=0.8442, PD(T)=0.1558\n",
            "\n",
            "=== Tenor 1.0Y ===\n",
            "Calibrated Gaussian rho_T: 0.5905\n",
            "Calibrated GVG params: {'rho_high': 0.5, 'rho_low': 0.2, 'p_high': 0.5, 'theta': 0.0, 'sigma': 1.0, 'nu': 1.0}\n",
            "\n",
            "Gaussian pricing vs market:\n",
            "      Tranche  Market      Model     Error Unit\n",
            "   equity_0_3  4.6922   4.692210  0.000010    %\n",
            "     mezz_3_7 52.9400 104.361868 51.421868  bps\n",
            "    mezz_7_10 21.6200  48.476118 26.856118  bps\n",
            " senior_10_15  5.2100  25.539764 20.329764  bps\n",
            "senior_15_100  4.7800   1.515819 -3.264181  bps\n",
            "Gaussian MAE (mix units): 20.3744\n",
            "\n",
            "GVG pricing vs market:\n",
            "      Tranche  Market      Model     Error Unit\n",
            "   equity_0_3  4.6922   6.824841  2.132641    %\n",
            "     mezz_3_7 52.9400 123.496056 70.556056  bps\n",
            "    mezz_7_10 21.6200  74.013123 52.393123  bps\n",
            " senior_10_15  5.2100  52.567431 47.357431  bps\n",
            "senior_15_100  4.7800   9.325168  4.545168  bps\n",
            "GVG MAE (mix units): 35.3969\n",
            "\n",
            "=== Tenor 2.0Y ===\n",
            "Calibrated Gaussian rho_T: 0.6126\n",
            "Calibrated GVG params: {'rho_high': 0.5000007723732374, 'rho_low': 0.20000223647747115, 'p_high': 0.49999882870461065, 'theta': 0.0, 'sigma': 1.0, 'nu': 1.0}\n",
            "\n",
            "Gaussian pricing vs market:\n",
            "      Tranche    Market      Model     Error Unit\n",
            "   equity_0_3 10.106963  10.106966  0.000003    %\n",
            "     mezz_3_7 90.940000 157.784319 66.844319  bps\n",
            "    mezz_7_10 40.630000  84.625869 43.995869  bps\n",
            " senior_10_15 14.330000  49.899881 35.569881  bps\n",
            "senior_15_100  8.300000   3.800032 -4.499968  bps\n",
            "Gaussian MAE (mix units): 30.1820\n",
            "\n",
            "GVG pricing vs market:\n",
            "      Tranche    Market     Model     Error Unit\n",
            "   equity_0_3 10.106963 12.815848  2.708885    %\n",
            "     mezz_3_7 90.940000 94.770788  3.830788  bps\n",
            "    mezz_7_10 40.630000 55.299455 14.669455  bps\n",
            " senior_10_15 14.330000 36.795648 22.465648  bps\n",
            "senior_15_100  8.300000  6.986865 -1.313135  bps\n",
            "GVG MAE (mix units): 8.9976\n",
            "\n",
            "=== Tenor 3.0Y ===\n",
            "Calibrated Gaussian rho_T: 0.6218\n",
            "Calibrated GVG params: {'rho_high': 0.5000009274872447, 'rho_low': 0.20000164146055416, 'p_high': 0.5000009849335133, 'theta': 0.0, 'sigma': 1.0, 'nu': 1.0}\n",
            "\n",
            "Gaussian pricing vs market:\n",
            "      Tranche     Market      Model     Error Unit\n",
            "   equity_0_3  16.455602  16.455599 -0.000003    %\n",
            "     mezz_3_7 133.100000 208.878774 75.778774  bps\n",
            "    mezz_7_10  63.540000 121.670666 58.130666  bps\n",
            " senior_10_15  26.450000  76.634812 50.184812  bps\n",
            "senior_15_100  12.730000   6.808145 -5.921855  bps\n",
            "Gaussian MAE (mix units): 38.0032\n",
            "\n",
            "GVG pricing vs market:\n",
            "      Tranche     Market      Model     Error Unit\n",
            "   equity_0_3  16.455602  24.072105  7.616503    %\n",
            "     mezz_3_7 133.100000 142.900854  9.800854  bps\n",
            "    mezz_7_10  63.540000  55.932550 -7.607450  bps\n",
            " senior_10_15  26.450000  36.196685  9.746685  bps\n",
            "senior_15_100  12.730000   6.152193 -6.577807  bps\n",
            "GVG MAE (mix units): 8.2699\n",
            "\n",
            "=== Tenor 5.0Y ===\n",
            "Calibrated Gaussian rho_T: 0.6374\n",
            "Calibrated GVG params: {'rho_high': 0.5000048393364287, 'rho_low': 0.20000806556071457, 'p_high': 0.5000048393364287, 'theta': 0.0, 'sigma': 1.0, 'nu': 1.0}\n",
            "\n",
            "Gaussian pricing vs market:\n",
            "      Tranche   Market      Model      Error Unit\n",
            "   equity_0_3  28.3014  28.301466   0.000066    %\n",
            "     mezz_3_7  95.0800 275.123356 180.043356  bps\n",
            "    mezz_7_10 113.1000 177.262057  64.162057  bps\n",
            " senior_10_15  55.9400 121.107922  65.167922  bps\n",
            "senior_15_100  21.7200  13.280911  -8.439089  bps\n",
            "Gaussian MAE (mix units): 63.5625\n",
            "\n",
            "GVG pricing vs market:\n",
            "      Tranche   Market      Model      Error Unit\n",
            "   equity_0_3  28.3014  43.880023  15.578623    %\n",
            "     mezz_3_7  95.0800 246.694481 151.614481  bps\n",
            "    mezz_7_10 113.1000 108.892578  -4.207422  bps\n",
            " senior_10_15  55.9400  61.684052   5.744052  bps\n",
            "senior_15_100  21.7200   7.796733 -13.923267  bps\n",
            "GVG MAE (mix units): 38.2136\n",
            "\n",
            "=== Tenor 7.0Y ===\n",
            "Calibrated Gaussian rho_T: 0.6774\n",
            "Calibrated GVG params: {'rho_high': 0.4999992192834372, 'rho_low': 0.19999967036411795, 'p_high': 0.4999992192834372, 'theta': 0.0, 'sigma': 1.0, 'nu': 1.0}\n",
            "\n",
            "Gaussian pricing vs market:\n",
            "      Tranche    Market      Model      Error Unit\n",
            "   equity_0_3  42.25299  42.252991   0.000001    %\n",
            "     mezz_3_7 312.75000 377.993306  65.243306  bps\n",
            "    mezz_7_10 177.64000 270.211960  92.571960  bps\n",
            " senior_10_15  98.00000 201.872755 103.872755  bps\n",
            "senior_15_100  38.50000  28.759043  -9.740957  bps\n",
            "Gaussian MAE (mix units): 54.2858\n",
            "\n",
            "GVG pricing vs market:\n",
            "      Tranche    Market      Model      Error Unit\n",
            "   equity_0_3  42.25299  69.631695  27.378705    %\n",
            "     mezz_3_7 312.75000 476.505175 163.755175  bps\n",
            "    mezz_7_10 177.64000 238.187660  60.547660  bps\n",
            " senior_10_15  98.00000 126.029380  28.029380  bps\n",
            "senior_15_100  38.50000  10.765243 -27.734757  bps\n",
            "GVG MAE (mix units): 61.4891\n",
            "\n",
            "=== Tenor 10.0Y ===\n",
            "Calibrated Gaussian rho_T: 0.9900\n",
            "Calibrated GVG params: {'rho_high': 0.5000007908930987, 'rho_low': 0.2000013181006988, 'p_high': 0.5000007908794196, 'theta': 0.0, 'sigma': 1.0, 'nu': 1.0}\n",
            "\n",
            "Gaussian pricing vs market:\n",
            "      Tranche     Market      Model       Error Unit\n",
            "   equity_0_3 -52.426298  20.921411   73.347709    %\n",
            "     mezz_3_7 377.470000 181.230284 -196.239716  bps\n",
            "    mezz_7_10 228.020000 172.383303  -55.636697  bps\n",
            " senior_10_15 135.870000 164.618388   28.748388  bps\n",
            "senior_15_100  54.110000  68.896998   14.786998  bps\n",
            "Gaussian MAE (mix units): 73.7519\n",
            "\n",
            "GVG pricing vs market:\n",
            "      Tranche     Market      Model      Error Unit\n",
            "   equity_0_3 -52.426298  88.334980 140.761278    %\n",
            "     mezz_3_7 377.470000 720.931818 343.461818  bps\n",
            "    mezz_7_10 228.020000 357.986505 129.966505  bps\n",
            " senior_10_15 135.870000 201.974200  66.104200  bps\n",
            "senior_15_100  54.110000  17.501681 -36.608319  bps\n",
            "GVG MAE (mix units): 143.3804\n",
            "\n",
            "Done. 'results_by_tenor' now holds detailed comparison tables and parameters for each tenor.\n"
          ]
        }
      ],
      "source": [
        "# ================================================================\n",
        "# 0. Setup: imports & file paths\n",
        "# ================================================================\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import json\n",
        "from typing import List, Dict\n",
        "from dataclasses import dataclass\n",
        "from scipy.optimize import root_scalar, minimize_scalar, minimize\n",
        "from scipy.stats import norm\n",
        "\n",
        "np.random.seed(42)  # for reproducibility\n",
        "\n",
        "# In Colab: upload these two files to the working directory first.\n",
        "CDX_CONST_FILE = \"cdx_constituents_multi_tenor.csv\"\n",
        "CDX_MARKET_FILE = \"cdx_market_data_multi_tenor.json\"\n",
        "\n",
        "\n",
        "# ================================================================\n",
        "# 1. Load data\n",
        "# ================================================================\n",
        "\n",
        "# 1.1 Load constituents (we only need number of names & equal weights; recovery set to 40%)\n",
        "const_df = pd.read_csv(CDX_CONST_FILE)\n",
        "NUM_NAMES = len(const_df)\n",
        "weights = np.ones(NUM_NAMES) / NUM_NAMES\n",
        "RECOVERY_IDX = 0.40   # standard market convention for CDX\n",
        "\n",
        "print(f\"Loaded {NUM_NAMES} constituents.\")\n",
        "print(f\"Assumed index-level recovery: {RECOVERY_IDX:.2f}\")\n",
        "\n",
        "# 1.2 Load multi-tenor market data (index + tranches)\n",
        "with open(CDX_MARKET_FILE, \"r\") as f:\n",
        "    mkt_multi = json.load(f)\n",
        "\n",
        "# Available tenors in years (keys like \"1Y\",\"2Y\",...)\n",
        "available_tenors = sorted(mkt_multi.keys(), key=lambda x: float(x.replace(\"Y\", \"\")))\n",
        "print(\"Available tenors in JSON:\", available_tenors)\n",
        "\n",
        "# We focus on these standard tenors:\n",
        "TENORS_YEARS = [1.0, 2.0, 3.0, 5.0, 7.0, 10.0]\n",
        "\n",
        "# Extract index \"full_index\" spreads in bps for each tenor\n",
        "index_spreads_bps = []\n",
        "for T in TENORS_YEARS:\n",
        "    key = f\"{int(T)}Y\"\n",
        "    full_index = mkt_multi[key][\"full_index\"]  # in bps\n",
        "    index_spreads_bps.append(full_index)\n",
        "\n",
        "print(\"Index full_index spreads (bps) per tenor:\")\n",
        "for T, s in zip(TENORS_YEARS, index_spreads_bps):\n",
        "    print(f\"  {T:.0f}Y: {s:.4f} bps\")\n",
        "\n",
        "\n",
        "# ================================================================\n",
        "# 2. Discount Curve (simple, but standard structure)\n",
        "# ================================================================\n",
        "\n",
        "@dataclass\n",
        "class DiscountCurve:\n",
        "    \"\"\"\n",
        "    Simple discount curve with flat continuously-compounded zero rate.\n",
        "    For demonstration we assume a flat risk-free rate.\n",
        "    \"\"\"\n",
        "    flat_rate: float  # e.g. 0.03 for 3%\n",
        "\n",
        "    def df(self, t: float) -> float:\n",
        "        if t <= 0.0:\n",
        "            return 1.0\n",
        "        return np.exp(-self.flat_rate * t)\n",
        "\n",
        "    def dfs(self, ts: np.ndarray) -> np.ndarray:\n",
        "        return np.exp(-self.flat_rate * ts)\n",
        "\n",
        "\n",
        "# For demo: assume flat OIS at 3%\n",
        "disc_curve = DiscountCurve(flat_rate=0.03)\n",
        "\n",
        "\n",
        "# ================================================================\n",
        "# 3. Standard CDS pricing & index hazard bootstrapping\n",
        "# ================================================================\n",
        "\n",
        "class CDSBootstrapper:\n",
        "    \"\"\"\n",
        "    Bootstrap piecewise-constant hazard rates from index CDS spreads\n",
        "    using standard CDS pricing equations:\n",
        "\n",
        "        PV_prem = S * sum(Δt * DF(t_i) * Q(t_i))\n",
        "        PV_prot = (1-R) * sum(DF(t_i) * [Q(t_{i-1}) - Q(t_i)])\n",
        "\n",
        "    where hazard is piecewise-constant by tenor.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, disc: DiscountCurve, recovery: float = 0.40, freq: int = 4):\n",
        "        self.disc = disc\n",
        "        self.R = recovery\n",
        "        self.freq = freq\n",
        "\n",
        "    @staticmethod\n",
        "    def _lambda_for_time(t: float,\n",
        "                         segment_tenors: List[float],\n",
        "                         segment_lambdas: List[float]) -> float:\n",
        "        \"\"\"\n",
        "        Given time t, find which tenor segment it belongs to, and return the corresponding lambda.\n",
        "        Segments are defined by increasing tenor boundaries: [T1, T2, ..., Tn].\n",
        "        On (0, T1] -> lambda_1, on (T1, T2] -> lambda_2, etc.\n",
        "        \"\"\"\n",
        "        for idx, T in enumerate(segment_tenors):\n",
        "            if t <= T + 1e-12:\n",
        "                return segment_lambdas[idx]\n",
        "        return segment_lambdas[-1]\n",
        "\n",
        "    def _build_survival_curve(self,\n",
        "                              coupons: np.ndarray,\n",
        "                              segment_tenors: List[float],\n",
        "                              segment_lambdas: List[float]) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Compute survival Q(t_i) at each coupon time using piecewise-constant hazard rates.\n",
        "        \"\"\"\n",
        "        surv = np.zeros_like(coupons, dtype=float)\n",
        "        cum_intensity = 0.0\n",
        "        prev_t = 0.0\n",
        "\n",
        "        for i, t in enumerate(coupons):\n",
        "            lam = self._lambda_for_time(t, segment_tenors, segment_lambdas)\n",
        "            dt = t - prev_t\n",
        "            cum_intensity += lam * dt\n",
        "            surv[i] = np.exp(-cum_intensity)\n",
        "            prev_t = t\n",
        "\n",
        "        return surv\n",
        "\n",
        "    def _cds_pv_equation(self,\n",
        "                         spread_dec: float,\n",
        "                         T: float,\n",
        "                         known_tenors: List[float],\n",
        "                         known_lambdas: List[float],\n",
        "                         lambda_new: float) -> float:\n",
        "        \"\"\"\n",
        "        Given known hazard segments (for previous tenors), and a trial lambda for the new segment,\n",
        "        compute PV_prem - PV_prot for target maturity T.\n",
        "        Root of this function w.r.t lambda_new yields the correct hazard rate for [T_{k-1}, T_k].\n",
        "        \"\"\"\n",
        "        segment_tenors = known_tenors + [T]\n",
        "        segment_lambdas = known_lambdas + [lambda_new]\n",
        "\n",
        "        dt = 1.0 / self.freq\n",
        "        coupons = np.arange(dt, T + 1e-12, dt)\n",
        "\n",
        "        dfs = self.disc.dfs(coupons)\n",
        "        surv = self._build_survival_curve(coupons, segment_tenors, segment_lambdas)\n",
        "\n",
        "        # Premium leg\n",
        "        pv_prem = np.sum(spread_dec * dt * dfs * surv)\n",
        "\n",
        "        # Protection leg\n",
        "        surv_prev = np.concatenate(([1.0], surv[:-1]))\n",
        "        default_prob = surv_prev - surv\n",
        "        pv_prot = np.sum((1.0 - self.R) * dfs * default_prob)\n",
        "\n",
        "        return pv_prem - pv_prot\n",
        "\n",
        "    def bootstrap_index_hazard(self,\n",
        "                               tenors: List[float],\n",
        "                               spreads_bps: List[float]) -> Dict[float, float]:\n",
        "        \"\"\"\n",
        "        Bootstrap piecewise-constant hazard rates from index CDS spreads.\n",
        "\n",
        "        tenors: [1, 2, 3, 5, 7, 10]\n",
        "        spreads_bps: index spreads in bps for these tenors.\n",
        "        return: {T_k: lambda_k} where lambda_k is intensity on (T_{k-1}, T_k].\n",
        "        \"\"\"\n",
        "        tenors = list(tenors)\n",
        "        spreads_bps = list(spreads_bps)\n",
        "\n",
        "        known_tenors: List[float] = []\n",
        "        known_lambdas: List[float] = []\n",
        "        hazard_by_tenor: Dict[float, float] = {}\n",
        "\n",
        "        for T, S_bps in zip(tenors, spreads_bps):\n",
        "            spread_dec = S_bps / 1e4  # bps -> decimal\n",
        "\n",
        "            def obj(lam_new):\n",
        "                return self._cds_pv_equation(spread_dec,\n",
        "                                             T,\n",
        "                                             known_tenors,\n",
        "                                             known_lambdas,\n",
        "                                             lam_new)\n",
        "\n",
        "            sol = root_scalar(obj, bracket=[1e-6, 10.0], method=\"brentq\")\n",
        "            lam_star = sol.root\n",
        "            known_tenors.append(T)\n",
        "            known_lambdas.append(lam_star)\n",
        "            hazard_by_tenor[T] = lam_star\n",
        "            print(f\"Bootstrapped lambda for tenor {T}Y: {lam_star:.4f}\")\n",
        "\n",
        "        return hazard_by_tenor\n",
        "\n",
        "\n",
        "# 3.1 Run hazard bootstrapping\n",
        "bootstrapper = CDSBootstrapper(disc_curve, recovery=RECOVERY_IDX, freq=4)\n",
        "hazard_curve = bootstrapper.bootstrap_index_hazard(TENORS_YEARS, index_spreads_bps)\n",
        "\n",
        "print(\"\\nPiecewise-constant hazard rates (index level):\")\n",
        "for T in sorted(hazard_curve.keys()):\n",
        "    print(f\"  (0, {T}Y] λ = {hazard_curve[T]:.4f}\")\n",
        "\n",
        "\n",
        "# ================================================================\n",
        "# 4. Survival & portfolio PD per tenor\n",
        "# ================================================================\n",
        "\n",
        "def index_survival_at_T(hazard_by_tenor: Dict[float, float], T: float) -> float:\n",
        "    \"\"\"\n",
        "    Compute index survival Q(T) given piecewise-constant hazard segments:\n",
        "      hazard_by_tenor: {T_k: lambda_k} for segments (T_{k-1}, T_k].\n",
        "    \"\"\"\n",
        "    tenors_sorted = sorted(hazard_by_tenor.keys())\n",
        "    cum_int = 0.0\n",
        "    prev = 0.0\n",
        "\n",
        "    for Tk in tenors_sorted:\n",
        "        lam = hazard_by_tenor[Tk]\n",
        "        seg_start = prev\n",
        "        seg_end = Tk\n",
        "        if T <= seg_start:\n",
        "            break\n",
        "        dt = min(T, seg_end) - seg_start\n",
        "        if dt > 0:\n",
        "            cum_int += lam * dt\n",
        "        prev = seg_end\n",
        "        if Tk >= T:\n",
        "            break\n",
        "\n",
        "    return float(np.exp(-cum_int))\n",
        "\n",
        "\n",
        "PD_by_tenor: Dict[float, float] = {}\n",
        "for T in TENORS_YEARS:\n",
        "    Q_T = index_survival_at_T(hazard_curve, T)\n",
        "    PD_T = 1.0 - Q_T\n",
        "    PD_by_tenor[T] = PD_T\n",
        "    print(f\"Tenor {T}Y: Q(T)={Q_T:.4f}, PD(T)={PD_T:.4f}\")\n",
        "\n",
        "\n",
        "# ================================================================\n",
        "# 5. Gaussian Copula tranche pricer\n",
        "# ================================================================\n",
        "\n",
        "class GaussianCopulaTranchePricer:\n",
        "    \"\"\"\n",
        "    One-factor Gaussian copula under LHP approximation for tranche loss at maturity.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, rho: float, n_points: int = 501):\n",
        "        self.rho = rho\n",
        "        self.Y = np.linspace(-5.0, 5.0, n_points)\n",
        "        pdf = norm.pdf(self.Y)\n",
        "        dy = self.Y[1] - self.Y[0]\n",
        "        self.weights = pdf * dy / np.sum(pdf * dy)\n",
        "\n",
        "    def conditional_pd(self, PD_T: float, y: float) -> float:\n",
        "        PD_T = np.clip(PD_T, 1e-8, 1.0 - 1e-8)\n",
        "        K = norm.ppf(PD_T)\n",
        "        num = K - np.sqrt(self.rho) * y\n",
        "        den = np.sqrt(1.0 - self.rho)\n",
        "        return float(norm.cdf(num / den))\n",
        "\n",
        "    def tranche_el(self,\n",
        "                   PD_T: float,\n",
        "                   attach: float,\n",
        "                   detach: float,\n",
        "                   recovery: float = 0.40) -> float:\n",
        "        \"\"\"\n",
        "        Expected tranche loss as fraction of tranche notional.\n",
        "        \"\"\"\n",
        "        lgd = 1.0 - recovery\n",
        "        width = detach - attach\n",
        "\n",
        "        losses = np.zeros_like(self.Y, dtype=float)\n",
        "        for i, y in enumerate(self.Y):\n",
        "            cond_pd = self.conditional_pd(PD_T, y)\n",
        "            L = lgd * cond_pd   # LHP approx\n",
        "            losses[i] = np.clip(L - attach, 0.0, width) / width\n",
        "\n",
        "        EL = float(np.sum(losses * self.weights))\n",
        "        return EL\n",
        "\n",
        "\n",
        "def fair_tranche_spread(discount_curve: DiscountCurve,\n",
        "                        maturity: float,\n",
        "                        EL_T: float,\n",
        "                        recovery: float = 0.40,\n",
        "                        freq: int = 4) -> float:\n",
        "    \"\"\"\n",
        "    Approximate fair running spread for a tranche given expected loss at maturity.\n",
        "    This is a standard approximation:\n",
        "      - premium leg uses average outstanding tranche notional\n",
        "      - protection leg approximated by EL_T discounted to T.\n",
        "    \"\"\"\n",
        "    dt = 1.0 / freq\n",
        "    payment_times = np.arange(dt, maturity + 1e-12, dt)\n",
        "    dfs = discount_curve.dfs(payment_times)\n",
        "\n",
        "    # Approximate average outstanding tranche notional\n",
        "    avg_notional = 1.0 - 0.5 * EL_T\n",
        "    risky_pv01 = float(np.sum(dfs * dt * avg_notional))\n",
        "\n",
        "    df_T = discount_curve.df(maturity)\n",
        "    pv_prot = EL_T * df_T\n",
        "\n",
        "    s = pv_prot / risky_pv01  # decimal (e.g. 0.02 = 200 bps)\n",
        "    return float(s)\n",
        "\n",
        "\n",
        "def price_tranches_gaussian(PD_T: float,\n",
        "                            rho: float,\n",
        "                            disc_curve: DiscountCurve,\n",
        "                            maturity: float,\n",
        "                            recovery: float = 0.40) -> Dict[str, Dict[str, float]]:\n",
        "    copula = GaussianCopulaTranchePricer(rho)\n",
        "    tr_defs = [\n",
        "        (\"equity_0_3\", 0.00, 0.03),\n",
        "        (\"mezz_3_7\",   0.03, 0.07),\n",
        "        (\"mezz_7_10\",  0.07, 0.10),\n",
        "        (\"senior_10_15\", 0.10, 0.15),\n",
        "        (\"senior_15_100\", 0.15, 1.00),\n",
        "    ]\n",
        "    results = {}\n",
        "    for name, A, B in tr_defs:\n",
        "        EL = copula.tranche_el(PD_T, A, B, recovery)\n",
        "        s = fair_tranche_spread(disc_curve, maturity, EL, recovery)\n",
        "        results[name] = {\"EL\": EL, \"spread\": s}\n",
        "    return results\n",
        "\n",
        "\n",
        "# ================================================================\n",
        "# 6. Variance-Gamma sampler + GVG Copula pricer\n",
        "# ================================================================\n",
        "\n",
        "def sample_variance_gamma(n: int, theta: float = 0.0, sigma: float = 1.0, nu: float = 1.0) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Sample n Variance-Gamma distributed values using standard construction:\n",
        "      G ~ Gamma(nu/2, scale=2/nu)\n",
        "      Z ~ N(0,1)\n",
        "      Y = theta * G + sigma * sqrt(G) * Z\n",
        "    \"\"\"\n",
        "    G = np.random.gamma(shape=nu / 2.0, scale=2.0 / nu, size=n)\n",
        "    Z = np.random.normal(size=n)\n",
        "    Y = theta * G + sigma * np.sqrt(G) * Z\n",
        "    return Y\n",
        "\n",
        "\n",
        "class GVGCopulaTranchePricer:\n",
        "    \"\"\"\n",
        "    Mixed Gaussian + Variance-Gamma one-factor copula:\n",
        "      - with prob p_high: VG factor with rho_high (high-corr, fat-tail regime)\n",
        "      - with prob (1 - p_high): Gaussian factor with rho_low (low-corr regime)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 rho_high: float,\n",
        "                 rho_low: float,\n",
        "                 p_high: float,\n",
        "                 theta: float = 0.0,\n",
        "                 sigma: float = 1.0,\n",
        "                 nu: float = 1.0,\n",
        "                 n_points: int = 2000):\n",
        "        self.rho_high = rho_high\n",
        "        self.rho_low = rho_low\n",
        "        self.p_high = p_high\n",
        "        self.theta = theta\n",
        "        self.sigma = sigma\n",
        "        self.nu = nu\n",
        "\n",
        "        n_high = int(n_points * p_high)\n",
        "        n_low = n_points - n_high\n",
        "\n",
        "        # High-correlation VG regime\n",
        "        Y_high = sample_variance_gamma(\n",
        "            n=n_high,\n",
        "            theta=self.theta,\n",
        "            sigma=self.sigma,\n",
        "            nu=self.nu\n",
        "        )\n",
        "\n",
        "        # Low-correlation Gaussian regime\n",
        "        Y_low = np.random.normal(size=n_low)\n",
        "\n",
        "        self.Y = np.concatenate([Y_high, Y_low])\n",
        "        self.is_high = np.concatenate([\n",
        "            np.ones(n_high, dtype=bool),\n",
        "            np.zeros(n_low, dtype=bool),\n",
        "        ])\n",
        "        self.weights = np.ones_like(self.Y, dtype=float) / len(self.Y)\n",
        "\n",
        "    def conditional_pd(self, PD_T: float, idx: int) -> float:\n",
        "        PD_T = np.clip(PD_T, 1e-8, 1.0 - 1e-8)\n",
        "        K = norm.ppf(PD_T)\n",
        "        y = self.Y[idx]\n",
        "        rho = self.rho_high if self.is_high[idx] else self.rho_low\n",
        "        num = K - np.sqrt(rho) * y\n",
        "        den = np.sqrt(1.0 - rho)\n",
        "        return float(norm.cdf(num / den))\n",
        "\n",
        "    def tranche_el(self,\n",
        "                   PD_T: float,\n",
        "                   attach: float,\n",
        "                   detach: float,\n",
        "                   recovery: float = 0.40) -> float:\n",
        "        lgd = 1.0 - recovery\n",
        "        width = detach - attach\n",
        "\n",
        "        losses = np.zeros_like(self.Y, dtype=float)\n",
        "        for i in range(len(self.Y)):\n",
        "            cond_pd = self.conditional_pd(PD_T, i)\n",
        "            L = lgd * cond_pd\n",
        "            losses[i] = np.clip(L - attach, 0.0, width) / width\n",
        "\n",
        "        EL = float(np.sum(losses * self.weights))\n",
        "        return EL\n",
        "\n",
        "\n",
        "def price_tranches_gvg(PD_T: float,\n",
        "                       params: Dict[str, float],\n",
        "                       disc_curve: DiscountCurve,\n",
        "                       maturity: float,\n",
        "                       recovery: float = 0.40) -> Dict[str, Dict[str, float]]:\n",
        "    pricer = GVGCopulaTranchePricer(\n",
        "        rho_high=params[\"rho_high\"],\n",
        "        rho_low=params[\"rho_low\"],\n",
        "        p_high=params[\"p_high\"],\n",
        "        theta=params.get(\"theta\", 0.0),\n",
        "        sigma=params.get(\"sigma\", 1.0),\n",
        "        nu=params.get(\"nu\", 1.0),\n",
        "        n_points=2000,\n",
        "    )\n",
        "    tr_defs = [\n",
        "        (\"equity_0_3\", 0.00, 0.03),\n",
        "        (\"mezz_3_7\",   0.03, 0.07),\n",
        "        (\"mezz_7_10\",  0.07, 0.10),\n",
        "        (\"senior_10_15\", 0.10, 0.15),\n",
        "        (\"senior_15_100\", 0.15, 1.00),\n",
        "    ]\n",
        "    results = {}\n",
        "    for name, A, B in tr_defs:\n",
        "        EL = pricer.tranche_el(PD_T, A, B, recovery)\n",
        "        s = fair_tranche_spread(disc_curve, maturity, EL, recovery)\n",
        "        results[name] = {\"EL\": EL, \"spread\": s}\n",
        "    return results\n",
        "\n",
        "\n",
        "# ================================================================\n",
        "# 7. Calibration & pricing error per tenor\n",
        "# ================================================================\n",
        "\n",
        "def get_market_tranche_quotes_for_tenor(tenor_years: float) -> Dict[str, float]:\n",
        "    \"\"\"\n",
        "    Extract market tranche quotes for a given tenor T from the JSON structure.\n",
        "    Returns:\n",
        "      {\n",
        "        'equity_0_3_upfront': float (%),\n",
        "        'equity_0_3_running': float (bps),\n",
        "        'mezz_3_7': float (bps),\n",
        "        'mezz_7_10': float (bps),\n",
        "        'senior_10_15': float (bps),\n",
        "        'senior_15_100': float (bps)\n",
        "      }\n",
        "    \"\"\"\n",
        "    key = f\"{int(tenor_years)}Y\"\n",
        "    d = mkt_multi[key]\n",
        "    out = {\n",
        "        \"equity_0_3_upfront\": d[\"equity_0_3_upfront\"],\n",
        "        \"equity_0_3_running\": d[\"equity_0_3_running\"],\n",
        "        \"mezz_3_7\": d[\"mezz_3_7\"],\n",
        "        \"mezz_7_10\": d[\"mezz_7_10\"],\n",
        "        \"senior_10_15\": d[\"senior_10_15\"],\n",
        "        \"senior_15_100\": d[\"senior_15_100\"],\n",
        "    }\n",
        "    return out\n",
        "\n",
        "\n",
        "def calibrate_gaussian_for_tenor(PD_T: float,\n",
        "                                 disc_curve: DiscountCurve,\n",
        "                                 maturity: float,\n",
        "                                 mkt_quotes: Dict[str, float],\n",
        "                                 recovery: float = 0.40) -> float:\n",
        "    \"\"\"\n",
        "    Calibrate single rho_T to match equity 0-3% upfront (simplified).\n",
        "    We approximate equity upfront as EL * 100 (%).\n",
        "    \"\"\"\n",
        "    target_upfront = mkt_quotes[\"equity_0_3_upfront\"]\n",
        "\n",
        "    def obj(rho):\n",
        "        if rho <= 0.0 or rho >= 1.0:\n",
        "            return 1e6\n",
        "        copula = GaussianCopulaTranchePricer(rho)\n",
        "        EL_eq = copula.tranche_el(PD_T, 0.0, 0.03, recovery)\n",
        "        model_upfront = EL_eq * 100.0\n",
        "        return (model_upfront - target_upfront) ** 2\n",
        "\n",
        "    res = minimize_scalar(obj, bounds=(0.01, 0.99), method=\"bounded\")\n",
        "    return float(res.x)\n",
        "\n",
        "\n",
        "def calibrate_gvg_for_tenor(PD_T: float,\n",
        "                            disc_curve: DiscountCurve,\n",
        "                            maturity: float,\n",
        "                            mkt_quotes: Dict[str, float],\n",
        "                            recovery: float = 0.40) -> Dict[str, float]:\n",
        "    \"\"\"\n",
        "    Calibrate GVG parameters (rho_high, rho_low, p_high).\n",
        "    VG tail parameters (theta, sigma, nu) fixed for now.\n",
        "\n",
        "    Objective: sum of squared errors across equity upfront and all mezz/senior spreads.\n",
        "    \"\"\"\n",
        "    target_upfront = mkt_quotes[\"equity_0_3_upfront\"]\n",
        "\n",
        "    def obj(theta_vec):\n",
        "        rho_high, rho_low, p_high = theta_vec\n",
        "        if not (0.0 < rho_low < 1.0 and 0.0 < rho_high < 1.0 and 0.0 < p_high < 1.0):\n",
        "            return 1e6\n",
        "\n",
        "        params = {\n",
        "            \"rho_high\": float(rho_high),\n",
        "            \"rho_low\": float(rho_low),\n",
        "            \"p_high\": float(p_high),\n",
        "            \"theta\": 0.0,\n",
        "            \"sigma\": 1.0,\n",
        "            \"nu\": 1.0,\n",
        "        }\n",
        "        model_prices = price_tranches_gvg(PD_T, params, disc_curve, maturity, recovery)\n",
        "\n",
        "        # Equity upfront (approx)\n",
        "        EL_eq = model_prices[\"equity_0_3\"][\"EL\"]\n",
        "        model_upfront = EL_eq * 100.0\n",
        "        err_eq = (model_upfront - target_upfront) ** 2\n",
        "\n",
        "        # Other tranches: compare running spread (bps)\n",
        "        err_others = 0.0\n",
        "        for name in [\"mezz_3_7\", \"mezz_7_10\", \"senior_10_15\", \"senior_15_100\"]:\n",
        "            s_model_bps = model_prices[name][\"spread\"] * 1e4\n",
        "            s_mkt_bps = mkt_quotes[name]\n",
        "            err_others += (s_model_bps - s_mkt_bps) ** 2\n",
        "\n",
        "        return err_eq + err_others\n",
        "\n",
        "    x0 = np.array([0.5, 0.2, 0.5])\n",
        "    bounds = [(0.05, 0.95), (0.01, 0.95), (0.05, 0.95)]\n",
        "\n",
        "    res = minimize(obj, x0=x0, bounds=bounds, method=\"L-BFGS-B\")\n",
        "    rho_high, rho_low, p_high = res.x\n",
        "\n",
        "    params = {\n",
        "        \"rho_high\": float(rho_high),\n",
        "        \"rho_low\": float(rho_low),\n",
        "        \"p_high\": float(p_high),\n",
        "        \"theta\": 0.0,\n",
        "        \"sigma\": 1.0,\n",
        "        \"nu\": 1.0,\n",
        "    }\n",
        "    return params\n",
        "\n",
        "\n",
        "def compute_pricing_errors_for_tenor(T: float,\n",
        "                                     PD_T: float,\n",
        "                                     disc_curve: DiscountCurve,\n",
        "                                     recovery: float = 0.40) -> Dict[str, object]:\n",
        "    \"\"\"\n",
        "    For a given tenor T:\n",
        "      - calibrate Gaussian rho_T\n",
        "      - calibrate GVG parameters\n",
        "      - price all tranches under both models\n",
        "      - compute pricing errors vs market quotes\n",
        "    Returns:\n",
        "      dict with DataFrames for Gaussian and GVG comparison tables and MAE metrics.\n",
        "    \"\"\"\n",
        "    mkt_quotes = get_market_tranche_quotes_for_tenor(T)\n",
        "\n",
        "    # 1) Gaussian calibration & pricing\n",
        "    rho_T = calibrate_gaussian_for_tenor(PD_T, disc_curve, T, mkt_quotes, recovery)\n",
        "    gauss_prices = price_tranches_gaussian(PD_T, rho_T, disc_curve, T, recovery)\n",
        "\n",
        "    # 2) GVG calibration & pricing\n",
        "    gvg_params = calibrate_gvg_for_tenor(PD_T, disc_curve, T, mkt_quotes, recovery)\n",
        "    gvg_prices = price_tranches_gvg(PD_T, gvg_params, disc_curve, T, recovery)\n",
        "\n",
        "    rows_gauss = []\n",
        "    rows_gvg = []\n",
        "\n",
        "    for name in [\"equity_0_3\", \"mezz_3_7\", \"mezz_7_10\", \"senior_10_15\", \"senior_15_100\"]:\n",
        "        if name == \"equity_0_3\":\n",
        "            # Upfront comparison (%)\n",
        "            mkt_val = mkt_quotes[\"equity_0_3_upfront\"]\n",
        "            model_gauss = gauss_prices[name][\"EL\"] * 100.0\n",
        "            model_gvg = gvg_prices[name][\"EL\"] * 100.0\n",
        "            unit = \"%\"\n",
        "        else:\n",
        "            # Running spread comparison (bps)\n",
        "            mkt_val = mkt_quotes[name]\n",
        "            model_gauss = gauss_prices[name][\"spread\"] * 1e4\n",
        "            model_gvg = gvg_prices[name][\"spread\"] * 1e4\n",
        "            unit = \"bps\"\n",
        "\n",
        "        rows_gauss.append({\n",
        "            \"Tranche\": name,\n",
        "            \"Market\": mkt_val,\n",
        "            \"Model\": model_gauss,\n",
        "            \"Error\": model_gauss - mkt_val,\n",
        "            \"Unit\": unit,\n",
        "        })\n",
        "        rows_gvg.append({\n",
        "            \"Tranche\": name,\n",
        "            \"Market\": mkt_val,\n",
        "            \"Model\": model_gvg,\n",
        "            \"Error\": model_gvg - mkt_val,\n",
        "            \"Unit\": unit,\n",
        "        })\n",
        "\n",
        "    df_gauss = pd.DataFrame(rows_gauss)\n",
        "    df_gvg = pd.DataFrame(rows_gvg)\n",
        "\n",
        "    mae_gauss = df_gauss[\"Error\"].abs().mean()\n",
        "    mae_gvg = df_gvg[\"Error\"].abs().mean()\n",
        "\n",
        "    print(f\"\\n=== Tenor {T}Y ===\")\n",
        "    print(f\"Calibrated Gaussian rho_T: {rho_T:.4f}\")\n",
        "    print(f\"Calibrated GVG params: {gvg_params}\")\n",
        "    print(\"\\nGaussian pricing vs market:\")\n",
        "    print(df_gauss.to_string(index=False))\n",
        "    print(f\"Gaussian MAE (mix units): {mae_gauss:.4f}\")\n",
        "\n",
        "    print(\"\\nGVG pricing vs market:\")\n",
        "    print(df_gvg.to_string(index=False))\n",
        "    print(f\"GVG MAE (mix units): {mae_gvg:.4f}\")\n",
        "\n",
        "    return {\n",
        "        \"gaussian\": df_gauss,\n",
        "        \"gvg\": df_gvg,\n",
        "        \"rho_gauss\": rho_T,\n",
        "        \"params_gvg\": gvg_params,\n",
        "        \"mae_gauss\": mae_gauss,\n",
        "        \"mae_gvg\": mae_gvg,\n",
        "    }\n",
        "\n",
        "\n",
        "# ================================================================\n",
        "# 8. Run experiment across all tenors\n",
        "# ================================================================\n",
        "\n",
        "results_by_tenor = {}\n",
        "\n",
        "for T in TENORS_YEARS:\n",
        "    PD_T = PD_by_tenor[T]\n",
        "    res_T = compute_pricing_errors_for_tenor(T, PD_T, disc_curve, RECOVERY_IDX)\n",
        "    results_by_tenor[T] = res_T\n",
        "\n",
        "print(\"\\nDone. 'results_by_tenor' now holds detailed comparison tables and parameters for each tenor.\")\n"
      ]
    }
  ]
}